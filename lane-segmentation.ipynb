{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2840219,"sourceType":"datasetVersion","datasetId":1724942},{"sourceId":12144207,"sourceType":"datasetVersion","datasetId":7648568},{"sourceId":437313,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":356732,"modelId":378036},{"sourceId":437348,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":356763,"modelId":378069}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n#                      FULL FINE-TUNING & INFERENCE SCRIPT (Corrected)\n# ==============================================================================\n# This script is self-contained. It loads a pre-trained model, fine-tunes it\n# on a higher resolution, and then runs inference on a folder of custom images.\n# ==============================================================================\n\n# --- Imports ---\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport cv2\nimport os\nimport json\nfrom tqdm import tqdm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport matplotlib.pyplot as plt\nimport glob\n\n# ==============================================================================\n# ### STEP 1: CONFIGURATION & SETUP ###\n# ==============================================================================\nprint(\"--- STEP 1: CONFIGURATION & SETUP ---\")\n\n# --- Paths ---\nPRE_TRAINED_MODEL_PATH = \"/kaggle/input/unet-lane/pytorch/default/1/unet_lane_detection_final.pth\"\nTUSIMPLE_DATA_PATH = \"/kaggle/input/tusimple/TUSimple/train_set/\"\nTRAIN_JSON = os.path.join(TUSIMPLE_DATA_PATH, 'label_data_0313.json')\nVAL_JSON = os.path.join(TUSIMPLE_DATA_PATH, 'label_data_0531.json')\nINFERENCE_IMAGE_FOLDER = \"/kaggle/input/traffic-dataset/traffic_wala_dataset/valid/images\"\nFT_MODEL_SAVE_PATH = \"/kaggle/working/unet_lane_FINETUNED.pth\"\n\n# --- Fine-Tuning Hyperparameters ---\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nFT_IMAGE_HEIGHT = 640\nFT_IMAGE_WIDTH  = 640\nFT_LEARNING_RATE = 1e-5\nFT_NUM_EPOCHS = 10\nFT_BATCH_SIZE = 1\n\nprint(f\"Using device: {DEVICE}\")\nprint(f\"Loading pre-trained model from: {PRE_TRAINED_MODEL_PATH}\")\n\n# ==============================================================================\n# ### STEP 2: HELPER CLASSES & FUNCTIONS (ALL DEFINITIONS HERE) ###\n# ==============================================================================\nprint(\"\\n--- STEP 2: DEFINING HELPER CLASSES & FUNCTIONS ---\")\n\n# --- Model Definition: U-NET ---\nclass DoubleConv(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.conv=nn.Sequential(nn.Conv2d(in_c, out_c, 3, 1, 1, bias=False), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True), nn.Conv2d(out_c, out_c, 3, 1, 1, bias=False), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))\n    def forward(self, x): return self.conv(x)\n\nclass UNET(nn.Module):\n    def __init__(self, in_c=3, out_c=1, fts=[64, 128, 256, 512]):\n        super().__init__()\n        self.ups, self.downs = nn.ModuleList(), nn.ModuleList(); self.pool = nn.MaxPool2d(2, 2)\n        for ft in fts: self.downs.append(DoubleConv(in_c, ft)); in_c = ft\n        for ft in reversed(fts):\n            self.ups.append(nn.ConvTranspose2d(ft*2, ft, 2, 2)); self.ups.append(DoubleConv(ft*2, ft))\n        self.bottleneck = DoubleConv(fts[-1], fts[-1]*2); self.final_conv = nn.Conv2d(fts[0], out_c, 1)\n    def forward(self, x):\n        skips = [];\n        for down in self.downs: x = down(x); skips.append(x); x = self.pool(x)\n        x = self.bottleneck(x); skips = skips[::-1]\n        for i in range(0, len(self.ups), 2):\n            x = self.ups[i](x); skip = skips[i//2]; x = torch.cat((skip, x), dim=1); x = self.ups[i+1](x)\n        return self.final_conv(x)\n\n# --- Dataset Class: TuSimpleLaneDataset ---\nclass TuSimpleLaneDataset(Dataset):\n    def __init__(self, data_path, json_path, transform=None):\n        self.data_path = data_path\n        self.transform = transform\n        self.samples = []\n        with open(json_path) as f:\n            for line in f:\n                sample_info = json.loads(line)\n                # Pre-filter to ensure files exist (makes it more robust)\n                image_path = os.path.join(self.data_path, sample_info['raw_file'])\n                mask_path = image_path.replace('/clips/', '/seg_label/').replace('.jpg', '.png')\n                if os.path.exists(image_path) and os.path.exists(mask_path):\n                    self.samples.append(sample_info)\n    def __len__(self): return len(self.samples)\n    def __getitem__(self, idx):\n        sample_info = self.samples[idx]\n        image_path = os.path.join(self.data_path, sample_info['raw_file'])\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask_path = image_path.replace('/clips/', '/seg_label/').replace('.jpg', '.png')\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        mask = (mask > 0).astype(\"float32\")\n        if self.transform:\n            augmented = self.transform(image=image, mask=mask)\n            image = augmented['image']\n            mask = augmented['mask'].unsqueeze(0)\n        return image, mask\n\n# --- Loss Function: DiceLoss ---\nclass DiceLoss(nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n    def forward(self, inputs, targets, smooth=1):\n        inputs = torch.sigmoid(inputs)\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        intersection = (inputs * targets).sum()\n        total_sum = inputs.sum() + targets.sum()\n        dice_coeff = (2.*intersection + smooth)/(total_sum + smooth)\n        return 1 - dice_coeff\n\n# --- Training & Validation Functions (These were missing before) ---\ndef train_fn(loader, model, optimizer, loss_fn):\n    loop = tqdm(loader, desc=\"Fine-Tuning\")\n    for data, targets in loop:\n        data, targets = data.to(device=DEVICE), targets.float().to(device=DEVICE)\n        predictions = model(data)\n        loss = loss_fn(predictions, targets)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        loop.set_postfix(dice_loss=loss.item())\n\ndef check_dice_score(loader, model, device=\"cuda\"):\n    model.eval()\n    total_intersection, total_sum_of_masks = 0, 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            preds = (torch.sigmoid(model(x)) > 0.5).float()\n            total_intersection += (preds * y).sum().item()\n            total_sum_of_masks += (preds.sum() + y.sum()).item()\n    final_dice_score = (2. * total_intersection) / (total_sum_of_masks + 1e-8)\n    model.train()\n    return final_dice_score\n\n# ==============================================================================\n# ### STEP 3: FINE-TUNING STAGE ###\n# ==============================================================================\nprint(\"\\n--- STEP 3: FINE-TUNING THE MODEL ---\")\n\n# Define the high-resolution transform\nfine_tune_transform = A.Compose([\n    A.LongestMaxSize(max_size=max(FT_IMAGE_HEIGHT, FT_IMAGE_WIDTH)),\n    A.PadIfNeeded(min_height=FT_IMAGE_HEIGHT, min_width=FT_IMAGE_WIDTH, border_mode=cv2.BORDER_CONSTANT),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n    A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n    ToTensorV2(),\n])\nft_val_transform = A.Compose([\n    A.LongestMaxSize(max_size=max(FT_IMAGE_HEIGHT, FT_IMAGE_WIDTH)),\n    A.PadIfNeeded(min_height=FT_IMAGE_HEIGHT, min_width=FT_IMAGE_WIDTH, border_mode=cv2.BORDER_CONSTANT),\n    A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n    ToTensorV2(),\n])\n\n# Create DataLoaders\nft_train_ds = TuSimpleLaneDataset(TUSIMPLE_DATA_PATH, TRAIN_JSON, transform=fine_tune_transform)\nft_val_ds = TuSimpleLaneDataset(TUSIMPLE_DATA_PATH, VAL_JSON, transform=ft_val_transform)\nft_train_loader = DataLoader(ft_train_ds, batch_size=FT_BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\nft_val_loader = DataLoader(ft_val_ds, batch_size=FT_BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n# Load the pre-trained model\nmodel = UNET(in_c=3, out_c=1).to(DEVICE)\nmodel.load_state_dict(torch.load(PRE_TRAINED_MODEL_PATH, map_location=DEVICE))\n\n# Set up for fine-tuning\noptimizer = optim.Adam(model.parameters(), lr=FT_LEARNING_RATE)\nloss_fn = DiceLoss()\nbest_ft_dice_score = -1.0\n    \n# Run the fine-tuning loop\nprint(\"Starting fine-tuning...\")\nfor epoch in range(FT_NUM_EPOCHS):\n    print(f\"--- Fine-Tuning Epoch {epoch+1}/{FT_NUM_EPOCHS} ---\")\n    train_fn(ft_train_loader, model, optimizer, loss_fn)\n    current_dice_score = check_dice_score(ft_val_loader, model, device=DEVICE)\n    print(f\"Validation Dice Score: {current_dice_score:.4f}\")\n    \n    if current_dice_score > best_ft_dice_score:\n        best_ft_dice_score = current_dice_score\n        torch.save(model.state_dict(), FT_MODEL_SAVE_PATH)\n        print(f\"--> New best fine-tuned model saved with Dice Score: {best_ft_dice_score:.4f}\")\n\nprint(f\"Fine-tuning finished. Best model saved to {FT_MODEL_SAVE_PATH}\")\n\n# ==============================================================================\n# ### STEP 4: INFERENCE ON YOUR CUSTOM IMAGES ###\n# ==============================================================================\nprint(\"\\n--- STEP 4: RUNNING INFERENCE ON CUSTOM IMAGE FOLDER ---\")\n\ndef predict_and_process_lanes_advanced(model, image_path, device):\n    \"\"\"\n    This advanced function runs the U-Net prediction and then uses a more\n    intelligent post-processing pipeline to merge broken lane segments.\n    \"\"\"\n    original_image = cv2.imread(image_path)\n    if original_image is None:\n        print(f\"Could not read image: {image_path}\"); return None, None\n        \n    model.eval() # Set model to evaluation mode for inference\n    original_dims = (original_image.shape[1], original_image.shape[0])\n    image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n    \n    # Use the same transform as validation during fine-tuning\n    transform = ft_val_transform\n    input_tensor = transform(image=image_rgb)['image'].unsqueeze(0).to(device)\n    \n    with torch.no_grad():\n        pred = torch.sigmoid(model(input_tensor)) > 0.5\n        # Resize the prediction mask back to the original image dimensions\n        raw_mask_resized = cv2.resize(pred.cpu().numpy().squeeze().astype(np.uint8), original_dims, interpolation=cv2.INTER_NEAREST)\n\n    # Post-processing to find and fit curves to lanes\n    kernel = np.ones((5, 5), np.uint8)\n    cleaned_mask = cv2.morphologyEx(raw_mask_resized, cv2.MORPH_OPEN, kernel, iterations=2)\n    num_labels, labels_mask, stats, _ = cv2.connectedComponentsWithStats(cleaned_mask, 4, cv2.CV_32S)\n    \n    final_lanes = []\n    output_image = original_image.copy()\n    for i in range(1, num_labels):\n        if stats[i, cv2.CC_STAT_AREA] < 300: continue\n        coords = np.argwhere(labels_mask == i)\n        y_coords, x_coords = coords[:, 0], coords[:, 1]\n        if len(y_coords) < 10: continue\n        poly_coeffs = np.polyfit(y_coords, x_coords, 2)\n        final_lanes.append(poly_coeffs)\n        plot_y = np.linspace(np.min(y_coords), np.max(y_coords), 100)\n        fit_x = np.polyval(poly_coeffs, plot_y)\n        points = np.asarray([fit_x, plot_y]).T.astype(np.int32)\n        color = np.random.randint(50, 255, size=3).tolist()\n        cv2.polylines(output_image, [points], isClosed=False, color=color, thickness=5)\n        \n    return output_image, final_lanes\n\n# Load the BEST fine-tuned model for inference\ninference_model = UNET(in_c=3, out_c=1).to(DEVICE)\nprint(f\"\\nLoading BEST fine-tuned model for final inference: {FT_MODEL_SAVE_PATH}\")\ninference_model.load_state_dict(torch.load(FT_MODEL_SAVE_PATH, map_location=DEVICE))\n\n# Get list of your images\nimage_paths = glob.glob(os.path.join(INFERENCE_IMAGE_FOLDER, \"*.jpg\"))\nprint(f\"Found {len(image_paths)} images in your folder.\")\n\n# Loop and process each image\nfor image_path in image_paths[:5]: # Process first 5 images as an example\n    print(f\"\\n--- Processing: {os.path.basename(image_path)} ---\")\n    \n    final_image, lane_data = predict_and_process_lanes_advanced(inference_model, image_path, DEVICE)\n    \n    if final_image is not None:\n        print(f\"Successfully identified {len(lane_data)} distinct lanes.\")\n        plt.figure(figsize=(15, 10))\n        plt.imshow(cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB))\n        plt.title(f\"Result for {os.path.basename(image_path)}\")\n        plt.axis(\"off\")\n        plt.show()\n\nprint(\"\\n--- Script Finished ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ### STEP 4: INFERENCE ON YOUR CUSTOM IMAGES ###\n# ==============================================================================\nprint(\"\\n--- STEP 4: RUNNING INFERENCE ON CUSTOM IMAGE FOLDER ---\")\n\ndef predict_and_process_lanes_advanced(model, image_path, device):\n    \"\"\"\n    This advanced function runs the U-Net prediction and then uses a more\n    intelligent post-processing pipeline to merge broken lane segments.\n    \"\"\"\n    original_image = cv2.imread(image_path)\n    if original_image is None:\n        print(f\"Could not read image: {image_path}\"); return None, None\n        \n    model.eval() # Set model to evaluation mode for inference\n    original_dims = (original_image.shape[1], original_image.shape[0])\n    image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n    \n    # Use the same transform as validation during fine-tuning\n    transform = ft_val_transform\n    input_tensor = transform(image=image_rgb)['image'].unsqueeze(0).to(device)\n    \n    with torch.no_grad():\n        pred = torch.sigmoid(model(input_tensor)) > 0.5\n        # Resize the prediction mask back to the original image dimensions\n        raw_mask_resized = cv2.resize(pred.cpu().numpy().squeeze().astype(np.uint8), original_dims, interpolation=cv2.INTER_NEAREST)\n# Post-processing to find and fit curves to lanes\n    kernel = np.ones((5, 5), np.uint8)\n    cleaned_mask = cv2.morphologyEx(raw_mask_resized, cv2.MORPH_OPEN, kernel, iterations=2)\n    num_labels, labels_mask, stats, _ = cv2.connectedComponentsWithStats(cleaned_mask, 4, cv2.CV_32S)\n    \n    final_lanes = []\n    output_image = original_image.copy()\n    for i in range(1, num_labels):\n        if stats[i, cv2.CC_STAT_AREA] < 300: continue\n        coords = np.argwhere(labels_mask == i)\n        y_coords, x_coords = coords[:, 0], coords[:, 1]\n        if len(y_coords) < 10: continue\n        poly_coeffs = np.polyfit(y_coords, x_coords, 2)\n        final_lanes.append(poly_coeffs)\n        plot_y = np.linspace(np.min(y_coords), np.max(y_coords), 100)\n        fit_x = np.polyval(poly_coeffs, plot_y)\n        points = np.asarray([fit_x, plot_y]).T.astype(np.int32)\n        color = np.random.randint(50, 255, size=3).tolist()\n        cv2.polylines(output_image, [points], isClosed=False, color=color, thickness=5)\n        \n    return output_image, final_lanes\n\n# Load the BEST fine-tuned model for inference\ninference_model = UNET(in_c=3, out_c=1).to(DEVICE)\nprint(f\"\\nLoading BEST fine-tuned model for final inference: {FT_MODEL_SAVE_PATH}\")\ninference_model.load_state_dict(torch.load(FT_MODEL_SAVE_PATH, map_location=DEVICE))\n\n# Get list of your images\nimage_paths = glob.glob(os.path.join(INFERENCE_IMAGE_FOLDER, \"*.jpg\"))\nprint(f\"Found {len(image_paths)} images in your folder.\")\n\n# Loop and process each image\nfor image_path in image_paths[:5]: # Process first 5 images as an example\n    print(f\"\\n--- Processing: {os.path.basename(image_path)} ---\")\n    \n    final_image, lane_data = predict_and_process_lanes_advanced(inference_model, image_path, DEVICE)\n    \n    if final_image is not None:\n        print(f\"Successfully identified {len(lane_data)} distinct lanes.\")\n        plt.figure(figsize=(15, 10))\n        plt.imshow(cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB))\n        plt.title(f\"Result for {os.path.basename(image_path)}\")\n        plt.axis(\"off\")\n        plt.show()\n\nprint(\"\\n--- Script Finished ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Define your UNET model here (or import it if defined elsewhere)\n# from model import UNET  # Uncomment if your UNET class is in a separate file\n\n# --- Paths ---\nINFERENCE_IMAGE_FOLDER = \"/kaggle/input/traffic-dataset/traffic_wala_dataset/valid/images\"\nMODEL_SAVE_PATH = \"/kaggle/input/unet-lane-finetuned-1/pytorch/default/1/unet_lane_FINETUNED.pth\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nIMAGE_HEIGHT = 640\nIMAGE_WIDTH = 640\n\ndef predict_lanes(model_path, image_path, device):\n    model = UNET(in_c=3, out_c=1)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n\n    image = cv2.imread(image_path)\n    if image is None:\n        print(f\"Failed to load image: {image_path}\")\n        return None, None\n\n    original_dims = (image.shape[1], image.shape[0])\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    transform = A.Compose([\n        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n        A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n        ToTensorV2(),\n    ])\n\n    augmented = transform(image=image_rgb)\n    input_tensor = augmented['image'].unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        pred = torch.sigmoid(model(input_tensor)) > 0.5\n        pred = pred.cpu().squeeze(0).squeeze(0).numpy()\n\n    mask = (pred * 255).astype(np.uint8)\n    mask_resized = cv2.resize(mask, original_dims, interpolation=cv2.INTER_NEAREST)\n\n    overlay = image.copy()\n    overlay[mask_resized != 0] = [0, 255, 0]\n    final_image = cv2.addWeighted(overlay, 0.4, image, 0.6, 0)\n\n    return final_image, mask_resized\n\n# --- Run inference on all images in the folder ---\nif os.path.exists(MODEL_SAVE_PATH):\n    image_paths = glob(os.path.join(INFERENCE_IMAGE_FOLDER, \"*.jpg\"))\n\n    for img_path in image_paths:\n        print(f\"\\nRunning inference on: {img_path}\")\n        predicted_image, _ = predict_lanes(MODEL_SAVE_PATH, img_path, DEVICE)\n\n        if predicted_image is not None:\n            plt.figure(figsize=(10, 6))\n            plt.imshow(cv2.cvtColor(predicted_image, cv2.COLOR_BGR2RGB))\n            plt.title(f\"Result: {os.path.basename(img_path)}\")\n            plt.axis(\"off\")\n            plt.show()\n        else:\n            print(\"Prediction failed.\")\nelse:\n    print(\"Model file not found. Skipping inference.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}